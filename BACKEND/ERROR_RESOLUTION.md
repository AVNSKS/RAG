# Error Resolution Report

## Date: January 15, 2026

---

## Overview
The project encountered multiple errors when running `python src/stage4_answer.py`. This document details all errors, their root causes, solutions implemented, and code changes made.

---

## Errors Encountered

### 1. **ChromaDB Internal Error: File exists (os error 17)**

#### Error Message:
```
chromadb.errors.InternalError: File exists (os error 17)
```

#### Root Cause:
- **Multiple ChromaDB instances** were being initialized across different modules (`stage2_retrieval.py`, `stage3_rerank.py`, `stage4_answer.py`)
- Each module was creating its own ChromaDB connection using `persist_directory` parameter
- ChromaDB was trying to create lock files that already existed, causing file system conflicts
- The `db/chroma_db` path was a **file instead of a directory**, preventing ChromaDB from initializing properly

#### Solution:
1. **Switched to PersistentClient pattern**: Used `chromadb.PersistentClient()` instead of passing `persist_directory` directly to `Chroma()`
2. **Removed duplicate initializations**: Imported the vectorstore instance from `stage2_retrieval.py` instead of creating new instances
3. **Fixed file/directory issue**: Deleted the `chroma_db` file and recreated it as a proper directory
4. **Added collection names**: Used explicit `collection_name="contracts_collection"` for consistency

---

### 2. **LangChain Deprecation Warning**

#### Warning Message:
```
LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9
```

#### Root Cause:
- Using old `langchain_community.vectorstores.Chroma` which is deprecated
- LangChain recommends using `langchain-chroma` package instead

#### Solution:
- **Updated to PersistentClient pattern** which is compatible with both old and new versions
- Added `chromadb` import and used `chromadb.PersistentClient(path=DB_PATH)`
- This approach works with current setup and is future-proof

---

### 3. **NameError: chatOllama not defined**

#### Error Message:
```
NameError: name 'chatOllama' is not defined
```

#### Root Cause:
- **Typo in variable name**: `chatOllama` instead of `ChatOllama` (case-sensitive)
- Python is case-sensitive, and the imported class is `ChatOllama` with capital letters

#### Solution:
- Fixed the typo from `chatOllama` to `ChatOllama` in `stage2_retrieval.py`

---

### 4. **ModuleNotFoundError: No module named 'rank_bm25'**

#### Error Message:
```
ModuleNotFoundError: No module named 'rank_bm25'
```

#### Root Cause:
- Missing dependency for hybrid search functionality
- The `rank-bm25` package provides BM25 algorithm for text ranking

#### Solution:
- Installed the package: `pip install rank-bm25`

---

### 5. **ModuleNotFoundError: No module named 'nltk'**

#### Error Message:
```
ModuleNotFoundError: No module named 'nltk'
```

#### Root Cause:
- Missing Natural Language Toolkit (NLTK) dependency
- Required for text processing in hybrid search

#### Solution:
- Installed the package: `pip install nltk`

---

### 6. **ModuleNotFoundError: No module named 'flag_embedding'**

#### Error Message:
```
ModuleNotFoundError: No module named 'flag_embedding'
```

#### Root Cause:
- **Incorrect import statement**: Used `from flag_embedding import FlagReranker`
- The actual package name is `FlagEmbedding` (capital F and E)
- Python package names are case-sensitive

#### Solution:
1. Installed the package: `pip install FlagEmbedding`
2. Fixed the import statement from `flag_embedding` to `FlagEmbedding`

---

### 7. **Ollama Connection Refused**

#### Error Message:
```
httpx.ConnectError: [Errno 61] Connection refused
```

#### Root Cause:
- Ollama server was not running
- The application requires Ollama to be active for LLM operations

#### Solution:
- Started Ollama service: `brew services start ollama`

---

## Second Round of Errors (After Initial Fixes)

### 8. **Ollama Model Not Found (404)**

#### Error Message:
```
ollama._types.ResponseError: model 'llama3.2:3b' not found (status code: 404)
```

#### Root Cause:
- Ollama server was running but the required model `llama3.2:3b` was not installed
- The application expects this specific model to be available locally
- Running `ollama list` showed no models were installed

#### Solution:
- Downloaded the required model: `ollama pull llama3.2:3b`
- Model downloaded successfully (2.0 GB)
- Verified model is now available in Ollama

---

### 9. **Variable Name Typo: vectorstore vs vectortores**

#### Error Message:
```
NameError: name 'vectorstore' is not defined. Did you mean: 'vectortores'?
```

#### Root Cause:
- **Typo in variable naming**: The vectorstore was initialized as `vectortores` (with typo) in line 16 of `stage2_retrieval.py`
- Multiple functions (`hyde_retrieve`, `hybrid_search`) were using `vectorstore` (correct spelling)
- Python couldn't find the variable because of the spelling mismatch

#### Solution:
- Fixed all references in `stage2_retrieval.py` to use `vectortores` (matching the initialized variable name)
- Updated in `hyde_retrieve()` function: `vectorstore.similarity_search_by_vector()` ‚Üí `vectortores.similarity_search_by_vector()`
- Updated in `hybrid_search()` function: 
  - `vectorstore.similarity_search()` ‚Üí `vectortores.similarity_search()`
  - `vectorstore.get()` ‚Üí `vectortores.get()`

---

### 10. **NLTK Data Download Timeout (Non-Critical)**

#### Warning Message:
```
[nltk_data] Error loading punkt: <urlopen error [Errno 60] Operation timed out>
```

#### Root Cause:
- NLTK trying to download 'punkt' tokenizer data from remote server
- Network timeout during download attempt
- Not critical as cached/local version was used successfully

#### Solution:
- No action required - application continued using cached data
- For future reference: Can manually download with `python -m nltk.downloader punkt`

---

## Code Changes Made

### File: `src/stage2_retrieval.py`

**Changes (First Round):**
1. Added `import chromadb` to use PersistentClient
2. Created PersistentClient instance before Chroma initialization
3. Updated Chroma initialization to use `client` parameter instead of `persist_directory`
4. Added explicit `collection_name` parameter
5. Fixed typo from `chatOllama` to `ChatOllama`

**Changes (Second Round):**
6. Fixed variable name typo in `hyde_retrieve()` function: `vectorstore` ‚Üí `vectortores`
7. Fixed variable name typo in `hybrid_search()` function (2 instances): `vectorstore` ‚Üí `vectortores`

### File: `src/stage3_rerank.py`

**Changes:**
1. Added `import chromadb` for PersistentClient pattern
2. Updated Chroma initialization with PersistentClient
3. Fixed import from `flag_embedding` to `FlagEmbedding`

### File: `src/stage4_answer.py`

**Changes:**
1. Imported `vectortores` and `llm` from `stage2_retrieval` module
2. Removed duplicate Chroma and ChatOllama initialization
3. Reused existing instances to avoid multiple ChromaDB connections

### File: `src/stage1_ingestion.py`

**Changes:**
1. Added `import chromadb` for consistency
2. Updated `Chroma.from_documents()` to use PersistentClient
3. Added explicit `collection_name` parameter
4. Removed deprecated `vectorstore.persist()` call (handled automatically)

---

## Dependencies Installed

| Package | Version | Purpose |
|---------|---------|---------|
| `rank-bm25` | 0.2.2 | BM25 ranking algorithm for hybrid search |
| `nltk` | 3.9.2 | Natural Language Toolkit for text processing |
| `FlagEmbedding` | 1.3.5 | Reranking model for improving retrieval quality |

---

## Summary of Resolution

### First Round Fixes:
‚úÖ **ChromaDB Errors**: Fixed by implementing PersistentClient pattern and removing duplicate initializations

‚úÖ **Missing Dependencies**: Installed 3 required packages (rank-bm25, nltk, FlagEmbedding)

‚úÖ **Import Errors**: Fixed typo in ChatOllama and corrected FlagEmbedding import

‚úÖ **File System Issue**: Removed incorrect file and created proper directory structure

‚úÖ **Ollama Connection**: Started Ollama service

### Second Round Fixes:
‚úÖ **Ollama Model Missing**: Downloaded llama3.2:3b model (2.0 GB)

‚úÖ **Variable Naming Typo**: Fixed all `vectorstore` references to match `vectortores` in stage2_retrieval.py

---

## Testing Results

### After First Round:
- ‚úÖ All modules import successfully
- ‚úÖ ChromaDB initializes without errors
- ‚úÖ Reranker model loads correctly
- ‚ö†Ô∏è Ollama model not found error

### After Second Round:
- ‚úÖ All modules import successfully
- ‚úÖ ChromaDB initializes without errors
- ‚úÖ Reranker model loads correctly
- ‚úÖ Ollama model loaded and responding
- ‚úÖ **Full RAG pipeline working successfully!**
- ‚úÖ Query rewriting functional
- ‚úÖ HyDE retrieval working
- ‚úÖ Reranking operational
- ‚úÖ Answer generation complete

**Sample Output:**
```
üöÄ FULL RAG PIPELINE:
Question: What is an Operating System?
   üé≠ Fake answer: According to standard industry practices and regulatory frameworks, an Operating...
   üìä Reranking 5 chunks...
   ‚úÖ Top scores: [-0.57, -0.01, -3.63]...

üí¨ An Operating System (OS) is system software that acts as an interface 
between users and computer hardware, managing resources such as processes, 
memory, files, and devices. (Context: "What is an Operating System?")
```

---

## Recommendations

1. **Update requirements.txt**: Add missing dependencies to prevent future issues
   - Add `rank-bm25==0.2.2`
   - Add `nltk==3.9.2`
   - Add `FlagEmbedding==1.3.5`
2. **Consider upgrading to langchain-chroma**: Install `pip install -U langchain-chroma` to use the new Chroma implementation
3. **Document Ollama requirement**: Add note that Ollama must be running with llama3.2:3b model
4. **Add error handling**: Implement try-catch blocks for ChromaDB and Ollama connection errors
5. **Fix variable naming**: Consider renaming `vectortores` to `vectorstore` for clarity and convention
6. **Pre-download NLTK data**: Add `nltk.download('punkt')` in setup script

---

## Prevention Strategies

1. **Singleton Pattern**: Create a single vectorstore instance and import it across modules ‚úÖ (Implemented)
2. **Dependency Management**: Keep requirements.txt updated with all packages
3. **Environment Setup Guide**: Create setup instructions for new developers
4. **Pre-flight Checks**: Add script to verify:
   - Ollama is running
   - Required model is downloaded
   - NLTK data is available
   - ChromaDB directory exists and is accessible
5. **Variable Naming Conventions**: Use consistent, typo-free naming throughout codebase

---

## Complete Error Timeline

1. **ChromaDB file lock error** ‚Üí Fixed with PersistentClient
2. **File vs directory issue** ‚Üí Recreated as proper directory
3. **chatOllama typo** ‚Üí Fixed to ChatOllama
4. **Missing rank-bm25** ‚Üí Installed
5. **Missing nltk** ‚Üí Installed
6. **Wrong flag_embedding import** ‚Üí Fixed to FlagEmbedding
7. **Ollama not running** ‚Üí Started service
8. **Ollama model not installed** ‚Üí Downloaded llama3.2:3b
9. **vectorstore vs vectortores typo** ‚Üí Fixed all references
10. **NLTK punkt download timeout** ‚Üí Non-critical, used cached data

**Final Status: ‚úÖ ALL ISSUES RESOLVED - Application fully functional!**
2. **Dependency Management**: Keep requirements.txt updated with all packages
3. **Environment Setup Guide**: Create setup instructions for new developers
4. **Pre-flight Checks**: Add script to verify all services are running before execution
